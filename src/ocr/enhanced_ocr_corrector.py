"""
ê°•í™”ëœ OCR í…ìŠ¤íŠ¸ ë³´ì • ëª¨ë“ˆ
PaddleOCRì˜ í•œê¸€ ì¸ì‹ ì˜¤ë¥˜ë¥¼ ìë™ìœ¼ë¡œ ë³´ì •í•˜ì—¬ "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤" íŒ¨í„´ì„ ì •í™•íˆ ê°ì§€
"""
from __future__ import annotations

import re
import logging
from difflib import SequenceMatcher
import unicodedata


class EnhancedOCRCorrector:
    """ê°•í™”ëœ OCR í…ìŠ¤íŠ¸ ë³´ì •ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # ê¸°ë³¸ íŠ¸ë¦¬ê±° íŒ¨í„´ë“¤
        self.base_patterns = [
            "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ì…ì¥í–ˆìŠµë‹ˆë‹¤", 
            "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤",
            "ì ‘ì†í–ˆìŠµë‹ˆë‹¤",
            "ì°¸ê°€í–ˆìŠµë‹ˆë‹¤"
        ]
        
        # OCR ì˜¤ì¸ì‹ íŒ¨í„´ ë§¤í•‘ (ì‹¤ì œ ê´€ì°°ëœ ì˜¤ë¥˜ë“¤)
        self.ocr_corrections = {
            # "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤" ë³€í˜•ë“¤
            "ë“¤ë¨¸ì™”ìŠµë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë‘˜ì–´ì™”ìŠµë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤", 
            "ë“¤ì–´ì™”ì‹œë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ëŠë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ìŠµë‹ˆíƒ€": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ìŠ¤ë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ìŠ´ë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ìë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ã……ë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ã…ë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”7ë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”5ë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "í‹€ì–´ì™”ìŠµë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ë¨¸ì™”ìë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™€ìŠµë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ìŠ´ë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            "ë“¤ì–´ì™”ë‹ˆë‹¤": "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
            
            # "ì…ì¥í–ˆìŠµë‹ˆë‹¤" ë³€í˜•ë“¤  
            "ì…ì •í–ˆìŠµë‹ˆë‹¤": "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
            "ì…ì¥í–¤ìŠµë‹ˆë‹¤": "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
            "ì…ì¥í–ˆìŠ¤ë‹ˆë‹¤": "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
            "ì…ì¥í–ˆìŠ´ë‹ˆë‹¤": "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
            "ì…ì¥í–ˆìë‹ˆë‹¤": "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
            "ì…ì í–ˆìŠµë‹ˆë‹¤": "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
            "ì…ì°½í–ˆìŠµë‹ˆë‹¤": "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
            
            # "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤" ë³€í˜•ë“¤
            "ì°¸ì–´í–ˆìŠµë‹ˆë‹¤": "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤",
            "ì°¸ì—¬í–¤ìŠµë‹ˆë‹¤": "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤", 
            "ì°¸ì—¬í–ˆìŠ¤ë‹ˆë‹¤": "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤",
            "ì°¸ì—¬í–ˆìŠ´ë‹ˆë‹¤": "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤",
            "ì°¸ì—¬í–ˆìë‹ˆë‹¤": "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤",
            "ì ì—¬í–ˆìŠµë‹ˆë‹¤": "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤",
            "ì°¸ì•¼í–ˆìŠµë‹ˆë‹¤": "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤"
        }
        
        # ë¬¸ìë³„ OCR ì˜¤ì¸ì‹ ë§¤í•‘
        self.char_corrections = {
            # ã…‡ê³„ì—´ ì˜¤ë¥˜
            'ë¨¸': ['ì–´', 'ë©°'],
            'ë©°': ['ì–´', 'ë¨¸'], 
            'ì–´': ['ë¨¸', 'ë©°'],
            
            # ã……ê³„ì—´ ì˜¤ë¥˜  
            'ìŠ¤': ['ìŠµ', 'ìŠ´'],
            'ìŠ´': ['ìŠµ', 'ìŠ¤'],
            'ìŠµ': ['ìŠ¤', 'ìŠ´', 'ã……', '5', '7'],
            'ã……': ['ìŠµ', 'ìŠ¤', '5', '7'],
            '5': ['ìŠµ', 'ã……', 's'],
            '7': ['ìŠµ', 'ã……', 't'],
            
            # ã„´ê³„ì—´ ì˜¤ë¥˜
            'ë‹ˆ': ['ëŠ', 'ã„´'],
            'ëŠ': ['ë‹ˆ', 'ã„´'],
            'ã„´': ['ë‹ˆ', 'ëŠ'],
            
            # ê¸°íƒ€ ìœ ì‚¬ ë¬¸ì
            'ì': ['ìŠµ', 'ì›'],
            'ì›': ['ì', 'ìŠµ'],
            'íƒ€': ['ë‹¤', 'ë”°'],
            'ë”°': ['ë‹¤', 'íƒ€'],
            'í‹€': ['ë“¤', 'ë¥¼'],
            'ë‘˜': ['ë“¤', 'íˆ´'],
            'ì •': ['ì¥', 'ì '],
            'ì ': ['ì°¸', 'ì '],
            'ì°½': ['ì¥', 'ì°½'],
            'ì–´': ['ë¨¸', 'ì—¬'],
            'ì•¼': ['ì—¬', 'ì–´']
        }
        
        # ìˆ«ì-í•œê¸€ í˜¼ë™ íŒ¨í„´
        self.number_char_map = {
            '0': ['ã…‡', 'â—‹'],
            '1': ['ã…£', 'ã„±', 'l', 'I'],
            '5': ['ã……', 's', 'S'],
            '7': ['ã……', 't', 'T'],
            '8': ['ã…‚', 'B']
        }
    
    def normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        if not text:
            return ""
        
        # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
        text = unicodedata.normalize('NFC', text)
        
        # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = re.sub(r'[^\wê°€-í£]', '', text)
        
        # ì—°ì†ëœ ë™ì¼ ë¬¸ì ì¶•ì•½ (ì˜ˆ: "ìŠµìŠµë‹ˆë‹¤" -> "ìŠµë‹ˆë‹¤")
        text = re.sub(r'(.)\1+', r'\1', text)
        
        return text.strip()
    
    def apply_direct_corrections(self, text: str) -> str:
        """ì§ì ‘ ë§¤í•‘ëœ ì˜¤ë¥˜ ë³´ì •"""
        normalized = self.normalize_text(text)
        
        # ì •í™•í•œ ë§¤ì¹­ë¶€í„° ì‹œë„
        for error, correct in self.ocr_corrections.items():
            if error in normalized:
                corrected = normalized.replace(error, correct)
                if corrected != normalized:
                    self.logger.debug(f"ì§ì ‘ ë³´ì •: '{text}' -> '{correct}' (íŒ¨í„´: {error})")
                    return correct
        
        return normalized
    
    def generate_character_variations(self, text: str) -> list[str]:
        """ë¬¸ìë³„ ë³€í˜• ìƒì„±"""
        variations = [text]
        
        # ê° ë¬¸ìì— ëŒ€í•´ ê°€ëŠ¥í•œ ì˜¤ì¸ì‹ ë³€í˜• ìƒì„±
        for i, char in enumerate(text):
            if char in self.char_corrections:
                new_variations = []
                for variation in variations:
                    for alt_char in self.char_corrections[char]:
                        new_var = variation[:i] + alt_char + variation[i+1:]
                        new_variations.append(new_var)
                variations.extend(new_variations)
        
        # ì¤‘ë³µ ì œê±°
        return list(set(variations))
    
    def fuzzy_match_patterns(self, text: str, threshold: float = 0.8) -> tuple[bool, str]:
        """í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ ìœ ì‚¬í•œ íŒ¨í„´ ì°¾ê¸°"""
        normalized = self.normalize_text(text)
        
        for pattern in self.base_patterns:
            similarity = SequenceMatcher(None, normalized, pattern).ratio()
            
            if similarity >= threshold:
                self.logger.debug(f"í¼ì§€ ë§¤ì¹­: '{text}' -> '{pattern}' (ìœ ì‚¬ë„: {similarity:.2f})")
                return True, pattern
        
        return False, ""
    
    def advanced_pattern_matching(self, text: str) -> tuple[bool, str]:
        """ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­"""
        normalized = self.normalize_text(text)
        
        # 1. í•µì‹¬ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
        core_keywords = {
            "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤": ["ë“¤", "ì–´", "ì™”", "ìŠµ", "ë‹ˆ", "ë‹¤"],
            "ì…ì¥í–ˆìŠµë‹ˆë‹¤": ["ì…", "ì¥", "í–ˆ", "ìŠµ", "ë‹ˆ", "ë‹¤"], 
            "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤": ["ì°¸", "ì—¬", "í–ˆ", "ìŠµ", "ë‹ˆ", "ë‹¤"]
        }
        
        for pattern, keywords in core_keywords.items():
            match_count = sum(1 for keyword in keywords if keyword in normalized)
            match_ratio = match_count / len(keywords)
            
            # 70% ì´ìƒ í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ë©´ í•´ë‹¹ íŒ¨í„´ìœ¼ë¡œ ì¸ì‹
            if match_ratio >= 0.7:
                self.logger.debug(f"í‚¤ì›Œë“œ ë§¤ì¹­: '{text}' -> '{pattern}' (ë§¤ì¹­ë¥ : {match_ratio:.2f})")
                return True, pattern
        
        # 2. ê¸¸ì´ ê¸°ë°˜ ë§¤ì¹­ (ë¹„ìŠ·í•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸)
        if 5 <= len(normalized) <= 8:  # "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤" ê¸¸ì´ ë²”ìœ„
            for pattern in self.base_patterns:
                if abs(len(normalized) - len(pattern)) <= 2:
                    # ë¬¸ì ë‹¨ìœ„ ìœ ì‚¬ë„ ê²€ì‚¬
                    common_chars = set(normalized) & set(pattern)
                    if len(common_chars) >= len(pattern) * 0.6:
                        self.logger.debug(f"ê¸¸ì´+ë¬¸ì ë§¤ì¹­: '{text}' -> '{pattern}'")
                        return True, pattern
        
        return False, ""
    
    def check_trigger_pattern(self, text: str) -> tuple[bool, str]:
        """ì¢…í•©ì ì¸ íŠ¸ë¦¬ê±° íŒ¨í„´ ê²€ì‚¬"""
        if not text or len(text.strip()) < 3:
            return False, ""
        
        original_text = text
        
        # 1ë‹¨ê³„: ì§ì ‘ ë³´ì • ì‹œë„
        corrected = self.apply_direct_corrections(text)
        for pattern in self.base_patterns:
            if pattern in corrected:
                self.logger.info(f"âœ… ì§ì ‘ ë³´ì • ë§¤ì¹­: '{original_text}' -> '{pattern}'")
                return True, pattern
        
        # 2ë‹¨ê³„: ë¬¸ì ë³€í˜• ê²€ì‚¬
        variations = self.generate_character_variations(self.normalize_text(text))
        for variation in variations:
            for pattern in self.base_patterns:
                if pattern in variation:
                    self.logger.info(f"âœ… ë¬¸ì ë³€í˜• ë§¤ì¹­: '{original_text}' -> '{pattern}' (ë³€í˜•: {variation})")
                    return True, pattern
        
        # 3ë‹¨ê³„: í¼ì§€ ë§¤ì¹­
        is_match, matched_pattern = self.fuzzy_match_patterns(text, threshold=0.75)
        if is_match:
            self.logger.info(f"âœ… í¼ì§€ ë§¤ì¹­: '{original_text}' -> '{matched_pattern}'")
            return True, matched_pattern
        
        # 4ë‹¨ê³„: ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­
        is_match, matched_pattern = self.advanced_pattern_matching(text)
        if is_match:
            self.logger.info(f"âœ… ê³ ê¸‰ ë§¤ì¹­: '{original_text}' -> '{matched_pattern}'")
            return True, matched_pattern
        
        # 5ë‹¨ê³„: ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ (ëŠìŠ¨í•œ ê²€ì‚¬)
        normalized = self.normalize_text(text)
        for pattern in self.base_patterns:
            # íŒ¨í„´ì˜ í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ
            if "ë“¤ì–´ì™”" in normalized or "ë“¤ë¨¸ì™”" in normalized or "ë‘˜ì–´ì™”" in normalized:
                self.logger.info(f"âœ… ë¶€ë¶„ ë§¤ì¹­: '{original_text}' -> 'ë“¤ì–´ì™”ìŠµë‹ˆë‹¤'")
                return True, "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤"
            elif "ì…ì¥" in normalized and "í–ˆ" in normalized:
                self.logger.info(f"âœ… ë¶€ë¶„ ë§¤ì¹­: '{original_text}' -> 'ì…ì¥í–ˆìŠµë‹ˆë‹¤'")
                return True, "ì…ì¥í–ˆìŠµë‹ˆë‹¤"
            elif "ì°¸ì—¬" in normalized and "í–ˆ" in normalized:
                self.logger.info(f"âœ… ë¶€ë¶„ ë§¤ì¹­: '{original_text}' -> 'ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤'")
                return True, "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤"
        
        return False, ""
    
    def add_custom_correction(self, error_text: str, correct_text: str):
        """ì‚¬ìš©ì ì •ì˜ ë³´ì • íŒ¨í„´ ì¶”ê°€"""
        self.ocr_corrections[error_text] = correct_text
        self.logger.info(f"ì‚¬ìš©ì ì •ì˜ ë³´ì • ì¶”ê°€: '{error_text}' -> '{correct_text}'")
    
    def correct_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ë³´ì • (í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ ë©”ì„œë“œ)"""
        return self.apply_direct_corrections(text)
    
    def get_correction_stats(self) -> dict[str, int]:
        """ë³´ì • í†µê³„ ë°˜í™˜"""
        return {
            "total_corrections": len(self.ocr_corrections),
            "base_patterns": len(self.base_patterns),
            "char_corrections": len(self.char_corrections)
        }


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_ocr_corrector():
    """OCR ë³´ì •ê¸° í…ŒìŠ¤íŠ¸"""
    corrector = EnhancedOCRCorrector()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        # ì •í™•í•œ í…ìŠ¤íŠ¸
        "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤",
        "ì…ì¥í–ˆìŠµë‹ˆë‹¤",
        "ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤",
        
        # ì¼ë°˜ì ì¸ OCR ì˜¤ë¥˜ë“¤
        "ë“¤ë¨¸ì™”ìŠµë‹ˆë‹¤",
        "ë‘˜ì–´ì™”ìŠµë‹ˆë‹¤", 
        "ë“¤ì–´ì™”ì‹œë‹ˆë‹¤",
        "ë“¤ì–´ì™”ëŠë‹ˆë‹¤",
        "ë“¤ì–´ì™”ìŠ´ë‹ˆë‹¤",
        "ë“¤ì–´ì™”ìë‹ˆë‹¤",
        "ë“¤ì–´ì™”ã……ë‹ˆë‹¤",
        "ë“¤ì–´ì™”7ë‹ˆë‹¤",
        "ë“¤ì–´ì™”5ë‹ˆë‹¤",
        "í‹€ì–´ì™”ìŠµë‹ˆë‹¤",
        
        # ê³µë°±ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ì í¬í•¨
        "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤.",
        "ë“¤ ì–´ ì™” ìŠµ ë‹ˆ ë‹¤",
        "ë“¤ì–´ì™”ìŠµë‹ˆë‹¤!!",
        
        # ë¶€ë¶„ ë§¤ì¹­ ì¼€ì´ìŠ¤
        "ë“¤ì–´ì™”",
        "ì…ì¥í–ˆ",
        "ì°¸ì—¬í–ˆ",
        
        # ë§¤ì¹­ë˜ì§€ ì•Šì•„ì•¼ í•  ì¼€ì´ìŠ¤
        "ì•ˆë…•í•˜ì„¸ìš”",
        "ë°˜ê°‘ìŠµë‹ˆë‹¤", 
        "ê°ì‚¬í•©ë‹ˆë‹¤"
    ]
    
    print("ğŸ§ª OCR ë³´ì •ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    for i, test_text in enumerate(test_cases, 1):
        is_match, matched_pattern = corrector.check_trigger_pattern(test_text)
        
        status = "âœ… ë§¤ì¹­" if is_match else "âŒ ë¹„ë§¤ì¹­"
        result = f"-> {matched_pattern}" if is_match else ""
        
        print(f"{i:2d}. '{test_text}' {status} {result}")
    
    print("\nğŸ“Š ë³´ì •ê¸° í†µê³„:")
    stats = corrector.get_correction_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")


if __name__ == "__main__":
    test_ocr_corrector()