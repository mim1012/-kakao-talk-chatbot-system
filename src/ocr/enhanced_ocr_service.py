"""
Enhanced OCR Service with improved detection capabilities
Fixes for empty OCR results and better preprocessing
"""
from __future__ import annotations

import cv2
import gc
import logging
import numpy as np
import re
import threading
import time
import sys
import os
from typing import Any
from core.config_manager import ConfigManager
from ocr.enhanced_ocr_corrector import EnhancedOCRCorrector
from utils.suppress_output import suppress_stdout_stderr

# Try to import OCR engines with graceful fallback
try:
    from paddleocr import PaddleOCR
    from ocr.safe_paddleocr import create_safe_paddleocr
    PADDLEOCR_AVAILABLE = True
except ImportError:
    PADDLEOCR_AVAILABLE = False
    logging.warning("PaddleOCR not available.")

try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False
    logging.warning("EasyOCR not available.")


class OCRResult:
    """Result of OCR processing with enhanced debugging."""
    
    def __init__(self, text: str = "", confidence: float = 0.0, position: tuple[int, int] | None = None, 
                 debug_info: dict[str, Any] | None = None):
        self.text = text
        self.confidence = confidence
        self.position = position or (0, 0)
        self.normalized_text = self._normalize_text(text)
        self.debug_info = debug_info or {}
    
    def _normalize_text(self, text: str) -> str:
        """Normalize text by removing spaces and special characters."""
        return re.sub(r'[^\wê°€-í£]', '', text)
    
    def is_valid(self) -> bool:
        """Check if the OCR result is valid."""
        return bool(self.text and self.confidence > 0)


class EnhancedOCRService:
    """Enhanced OCR service with better detection and recovery."""
    
    # Class-level lock for thread-safe PaddleOCR initialization
    _ocr_lock = threading.Lock()
    _shared_paddle_ocr = None
    _last_init_time = 0
    
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager
        self.logger = logging.getLogger(__name__)
        
        # Enhanced OCR corrector
        self.ocr_corrector = EnhancedOCRCorrector()
        self.logger.info("Enhanced OCR corrector initialized")
        
        # Debug mode temporarily enabled to check OCR results
        self.debug_mode = True
        self.debug_save_count = 0
        self.max_debug_saves = 0  # ë””ë²„ê·¸ ì €ì¥ ë¹„í™œì„±í™”
        self.save_preprocessed = False  # ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”
        
        # Performance metrics
        self.ocr_stats = {
            'total_attempts': 0,
            'successful_detections': 0,
            'empty_results': 0,
            'errors': 0,
            'last_error_time': 0
        }
        
        # OCR ì—”ì§„ ì´ˆê¸°í™” - configì— ë”°ë¼ ì„ íƒ
        self.use_easyocr = getattr(config_manager, 'use_easyocr', False)
        self.paddle_ocr = None
        self.easy_ocr = None
        
        # configì—ì„œ use_easyocr ê°’ì„ ì§ì ‘ í™•ì¸
        config_use_easyocr = config_manager.get('use_easyocr', False)
        
        if config_use_easyocr and EASYOCR_AVAILABLE:
            self._initialize_easy_ocr()
        elif PADDLEOCR_AVAILABLE:
            self._initialize_paddle_ocr()
        else:
            self.logger.error("No OCR engine available!")
    
    def _initialize_paddle_ocr(self) -> None:
        """Thread-safe PaddleOCR initialization with shared instance."""
        with EnhancedOCRService._ocr_lock:
            current_time = time.time()
            
            # Reuse existing instance if initialized recently (within 5 minutes)
            if (EnhancedOCRService._shared_paddle_ocr is not None and 
                current_time - EnhancedOCRService._last_init_time < 300):
                self.paddle_ocr = EnhancedOCRService._shared_paddle_ocr
                self.logger.info("Reusing existing PaddleOCR instance")
                return
            
            try:
                # Suppress all output during PaddleOCR initialization
                with suppress_stdout_stderr():
                    # Use safe PaddleOCR initialization for Python 3.11 compatibility
                    EnhancedOCRService._shared_paddle_ocr = create_safe_paddleocr()
                
                if EnhancedOCRService._shared_paddle_ocr is None:
                    # Fallback to basic initialization
                    EnhancedOCRService._shared_paddle_ocr = PaddleOCR(
                        lang='korean',
                        use_angle_cls=False,
                        enable_mkldnn=False
                    )
                
                self.paddle_ocr = EnhancedOCRService._shared_paddle_ocr
                EnhancedOCRService._last_init_time = current_time
                self.logger.info("PaddleOCR initialized successfully with enhanced settings")
                
            except Exception as e:
                self.logger.error(f"Failed to initialize PaddleOCR: {e}")
                self.paddle_ocr = None
    
    def _initialize_easy_ocr(self) -> None:
        """Initialize EasyOCR with Korean language support."""
        try:
            # EasyOCR ì´ˆê¸°í™”
            languages = getattr(self.config, 'easyocr_languages', ['ko'])
            self.easy_ocr = easyocr.Reader(languages, gpu=False)
            self.logger.info(f"EasyOCR initialized successfully with languages: {languages}")
        except Exception as e:
            self.logger.error(f"Failed to initialize EasyOCR: {e}")
            self.easy_ocr = None
    
    def _run_easyocr(self, image: np.ndarray) -> list:
        """Run EasyOCR and return results in a format compatible with PaddleOCR."""
        try:
            # EasyOCR ì‹¤í–‰
            results = self.easy_ocr.readtext(image)
            
            # EasyOCR ê²°ê³¼ë¥¼ PaddleOCR í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results = []
            for (bbox, text, confidence) in results:
                formatted_results.append([bbox, (text, confidence)])
            
            return [formatted_results] if formatted_results else []
            
        except Exception as e:
            self.logger.error(f"EasyOCR execution failed: {e}")
            return []
    
    def _extract_text_confidence(self, results: list) -> list[tuple[str, float]]:
        """Extract text and confidence pairs from OCR results (EasyOCR or PaddleOCR)."""
        text_confidence_pairs = []
        
        try:
            if not results or len(results) == 0:
                if self.debug_mode:
                    self.logger.info("ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                return text_confidence_pairs
            
            if self.debug_mode:
                self.logger.info(f"ê²°ê³¼ íŒŒì‹± ì‹œì‘ - ê²°ê³¼ ìˆ˜: {len(results)}")
            
            # PaddleX ìƒˆë¡œìš´ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ ì²˜ë¦¬ (v3.1.0+)
            if isinstance(results[0], dict) and 'rec_texts' in results[0] and 'rec_scores' in results[0]:
                rec_texts = results[0]['rec_texts']
                rec_scores = results[0]['rec_scores']
                text_confidence_pairs = list(zip(rec_texts, rec_scores))
                if len(text_confidence_pairs) > 0:
                    self.logger.info(f"PaddleX ë”•ì…”ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ íŒŒì‹±ë¨: {len(text_confidence_pairs)}ê°œ í…ìŠ¤íŠ¸")
                    for text, score in text_confidence_pairs:
                        self.logger.info(f"ê°ì§€ëœ í…ìŠ¤íŠ¸: '{text}' (ì‹ ë¢°ë„: {score:.2f})")
            # PaddleX ê°ì²´ í˜•ì‹ ì²˜ë¦¬ (ì´ì „ ë²„ì „)
            elif hasattr(results[0], 'rec_texts') and hasattr(results[0], 'rec_scores'):
                rec_texts = results[0].rec_texts
                rec_scores = results[0].rec_scores
                text_confidence_pairs = list(zip(rec_texts, rec_scores))
                if self.debug_mode:
                    self.logger.info(f"PaddleX ê°ì²´ í˜•ì‹ìœ¼ë¡œ íŒŒì‹±ë¨: {len(text_confidence_pairs)}ê°œ í…ìŠ¤íŠ¸")
            
            # í‘œì¤€ PaddleOCR/EasyOCR í˜•ì‹ ì²˜ë¦¬
            elif isinstance(results[0], list):
                if self.debug_mode:
                    self.logger.info(f"í‘œì¤€ í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì¤‘ - ì²« ë²ˆì§¸ ê²°ê³¼ ê¸¸ì´: {len(results[0])}")
                for line in results[0]:
                    if len(line) >= 2 and isinstance(line[1], tuple) and len(line[1]) >= 2:
                        text, confidence = line[1]
                        text_confidence_pairs.append((text, confidence))
                        if self.debug_mode:
                            self.logger.info(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: '{text}' (ì‹ ë¢°ë„: {confidence:.2f})")
            else:
                if self.debug_mode:
                    self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ê²°ê³¼ í˜•ì‹: {type(results[0])}")
            
            if self.debug_mode:
                self.logger.info(f"ìµœì¢… ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìˆ˜: {len(text_confidence_pairs)}")
            
            return text_confidence_pairs
            
        except Exception as e:
            self.logger.error(f"Failed to extract text/confidence: {e}")
            if self.debug_mode:
                self.logger.error(f"ê²°ê³¼ êµ¬ì¡°: {results}")
            return []
    
    def preprocess_image_enhanced(self, image: np.ndarray, cell_id: str = "") -> list[np.ndarray]:
        """Enhanced preprocessing with multiple strategies."""
        # ë¹ ë¥¸ ëª¨ë“œ í™•ì¸
        fast_mode = self.config.get('fast_ocr_mode', True)
        
        if fast_mode:
            return self._preprocess_fast(image, cell_id)
        
        # ê¸°ì¡´ì˜ ë³µì¡í•œ ì „ì²˜ë¦¬ (ë¹„í™œì„±í™”)
        return self._preprocess_full(image, cell_id)
    
    def _preprocess_fast(self, image: np.ndarray, cell_id: str = "") -> list[np.ndarray]:
        """ë¹ ë¥¸ ì „ì²˜ë¦¬ - ìµœì†Œí•œì˜ ì²˜ë¦¬ë§Œ"""
        preprocessed_images = []
        
        try:
            # RGBA ì²˜ë¦¬
            if len(image.shape) == 3 and image.shape[2] == 4:
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            else:
                gray = image.copy()
            
            # 1. ì›ë³¸ (ì´ë¯¸ ê¹¨ë—í•œ í…ìŠ¤íŠ¸ìš©)
            preprocessed_images.append(image.copy())
            
            # 2. ê°„ë‹¨í•œ ì´ì§„í™” (OTSU)
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            preprocessed_images.append(binary)
            
            # 3. í¬ê¸°ê°€ ì‘ìœ¼ë©´ 2ë°° í™•ëŒ€ í›„ ì´ì§„í™”
            height, width = gray.shape
            if width < 400 or height < 150:
                upscaled = cv2.resize(gray, (width * 2, height * 2), interpolation=cv2.INTER_LINEAR)
                _, binary_upscaled = cv2.threshold(upscaled, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                preprocessed_images.append(binary_upscaled)
            
            return preprocessed_images
            
        except Exception as e:
            self.logger.error(f"Fast preprocessing failed: {e}")
            return [image]
    
    def _preprocess_full(self, image: np.ndarray, cell_id: str = "") -> list[np.ndarray]:
        """ê¸°ì¡´ì˜ ì „ì²´ ì „ì²˜ë¦¬ (í˜„ì¬ ë¹„í™œì„±í™”)"""
        # ê¸°ì¡´ ì½”ë“œë¥¼ ì—¬ê¸°ë¡œ ì´ë™...
        preprocessed_images = []
        
        try:
            # Handle RGBA â†’ RGB conversion first
            if len(image.shape) == 3 and image.shape[2] == 4:
                # RGBA to RGB conversion
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
                self.logger.debug(f"Converted RGBA to RGB for {cell_id}")
            
            # Strategy 1: Original image (for already clear text)
            preprocessed_images.append(image.copy())
            
            # Convert to grayscale if needed  
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            else:
                gray = image.copy()
            
            # Strategy 2: Aggressive upscaling for Korean text
            height, width = gray.shape
            # ë” ì ê·¹ì ì¸ í™•ëŒ€ - ì¹´ì¹´ì˜¤í†¡ í…ìŠ¤íŠ¸ëŠ” ë³´í†µ ì‘ìŒ
            min_width, min_height = 600, 200  # ìµœì†Œ í¬ê¸° ì¦ê°€
            if width < min_width or height < min_height:
                scale_factor = max(min_width / width, min_height / height, 3.0)  # ìµœì†Œ 3ë°° í™•ëŒ€
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                upscaled = cv2.resize(gray, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                
                # ëŒ€ë¹„ í–¥ìƒ
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                enhanced = clahe.apply(upscaled)
                
                # Sharpen
                kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
                sharpened = cv2.filter2D(enhanced, -1, kernel)
                preprocessed_images.append(sharpened)
                
                if self.debug_mode:
                    self.logger.info(f"ì´ë¯¸ì§€ í™•ëŒ€: {width}x{height} â†’ {new_width}x{new_height} (x{scale_factor:.1f})")
            
            # Strategy 3: Adaptive threshold with different parameters
            for block_size in [11, 15]:
                for C in [2, 5]:
                    try:
                        binary = cv2.adaptiveThreshold(
                            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                            cv2.THRESH_BINARY, block_size, C
                        )
                        preprocessed_images.append(binary)
                        
                        # Also try inverted
                        inverted = cv2.bitwise_not(binary)
                        preprocessed_images.append(inverted)
                    except:
                        continue
            
            # Strategy 4: OTSU thresholding
            _, otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            preprocessed_images.append(otsu)
            
            # Strategy 5: Contrast enhancement
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            preprocessed_images.append(enhanced)
            
            # Debug image saving disabled to prevent clutter
            
            return preprocessed_images
            
        except Exception as e:
            self.logger.error(f"Image preprocessing failed for {cell_id}: {e}")
            return [image]  # Return original if preprocessing fails
    
    def _save_debug_images(self, images: list[np.ndarray], cell_id: str):
        """Debug image saving disabled."""
        pass  # ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”
    
    def perform_ocr_with_recovery(self, image: np.ndarray, cell_id: str = "") -> OCRResult:
        """Perform OCR with automatic recovery and multiple strategies."""
        self.ocr_stats['total_attempts'] += 1
        
        # Check if OCR engine needs recovery
        if not self._check_ocr_health():
            self._recover_ocr_engine()
        
        if not self.paddle_ocr and not self.easy_ocr:
            self.logger.warning("No OCR engine available")
            self.ocr_stats['errors'] += 1
            return OCRResult(debug_info={'error': 'OCR not available'})
        
        try:
            # Garbage collection before OCR
            gc.collect()
            
            # ì´ë¯¸ì§€ ì •ë³´ ë¡œê¹…
            if self.debug_mode:
                self.logger.info(f"OCR ì‹œì‘ - {cell_id}: ì´ë¯¸ì§€ í¬ê¸° {image.shape}, í‰ê· ê°’: {image.mean():.1f}")
            
            # Get multiple preprocessed versions
            preprocessed_images = self.preprocess_image_enhanced(image, cell_id)
            
            if self.debug_mode:
                self.logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ - {cell_id}: {len(preprocessed_images)}ê°œ ì´ë¯¸ì§€ ìƒì„±")
            
            best_result = None
            best_confidence = -1  # -1ë¡œ ì´ˆê¸°í™”í•˜ì—¬ ëª¨ë“  ê²°ê³¼ê°€ ê³ ë ¤ë˜ë„ë¡ í•¨
            all_results = []
            trigger_results = []  # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ í¬í•¨ëœ ê²°ê³¼ë“¤
            
            # Try OCR on each preprocessed image
            for i, processed_img in enumerate(preprocessed_images):
                try:
                    # Use PaddleOCR (EasyOCR disabled)
                    if self.debug_mode:
                        self.logger.info(f"PaddleOCR ì‹¤í–‰ ì¤‘ - {cell_id} Strategy {i}")
                    
                    results = self.paddle_ocr.ocr(processed_img)
                    
                    if self.debug_mode:
                        self.logger.info(f"PaddleOCR ê²°ê³¼ - {cell_id} Strategy {i}: {len(results) if results else 0}ê°œ ê²°ê³¼")
                        if results:
                            self.logger.info(f"ê²°ê³¼ íƒ€ì…: {type(results)}, ì²« ë²ˆì§¸ ê²°ê³¼: {type(results[0]) if results else 'None'}")
                    
                    if results and len(results) > 0:
                        # í†µí•©ëœ ê²°ê³¼ ì²˜ë¦¬ (EasyOCR/PaddleOCR ëª¨ë‘ ì§€ì›)
                        text_confidence_pairs = self._extract_text_confidence(results)
                        
                        # ëª¨ë“  ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¡œê·¸ ì¶œë ¥
                        if text_confidence_pairs:
                            print(f"\nğŸ” [OCR ê°ì§€] Strategy {i} - {len(text_confidence_pairs)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬:")
                            for idx, (t, c) in enumerate(text_confidence_pairs):
                                print(f"   [{idx}] '{t}' (ì‹ ë¢°ë„: {c:.2f})")
                        
                        for j, (text, confidence) in enumerate(text_confidence_pairs):
                                # ë¡œê·¸ í…ìŠ¤íŠ¸ í•„í„°ë§
                                if self._is_log_text(text):
                                    if self.debug_mode:
                                        self.logger.debug(f"{cell_id}: ë¡œê·¸ í…ìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸° - '{text}'")
                                    continue
                                
                                # Log only high confidence detections in debug mode
                                if self.debug_mode and confidence > 0.7:
                                    self.logger.debug(f"{cell_id} Strategy {i}: '{text}' (conf: {confidence:.2f})")
                                
                                all_results.append({
                                    'text': text,
                                    'confidence': confidence,
                                    'strategy': i
                                })
                                
                                # Update best result
                                # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒ
                                is_trigger_text = any(pattern in text for pattern in self.config.get('trigger_patterns', []))
                                
                                # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ìˆê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë” ë†’ì€ ê²½ìš° ì—…ë°ì´íŠ¸
                                should_update = False
                                if is_trigger_text and confidence > 0.3:
                                    # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ìˆìœ¼ë©´ ë‚®ì€ ì‹ ë¢°ë„(0.3)ë„ í—ˆìš©
                                    should_update = True
                                elif confidence > best_confidence and not any(pattern in best_result.text if best_result else '' for pattern in self.config.get('trigger_patterns', [])):
                                    # í˜„ì¬ ìµœê³  ê²°ê³¼ê°€ íŠ¸ë¦¬ê±°ê°€ ì•„ë‹ˆê³ , ìƒˆ ê²°ê³¼ê°€ ë” ë†’ì€ ì‹ ë¢°ë„ë©´ ì„ íƒ
                                    should_update = True
                                
                                if should_update:
                                    best_confidence = confidence
                                    # PaddleX í˜•ì‹ì—ì„œëŠ” positionì„ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
                                    position = (0, 0)  # ê¸°ë³¸ê°’
                                    if hasattr(results[0], 'rec_polys') and len(results[0].rec_polys) > j:
                                        poly = results[0].rec_polys[j]
                                        if len(poly) > 0:
                                            position = (int(poly[0][0]), int(poly[0][1]))
                                    
                                    best_result = OCRResult(
                                        text, 
                                        confidence, 
                                        position,
                                        debug_info={
                                            'strategy': i,
                                            'all_results': all_results
                                        }
                                    )
                        else:
                            # ê¸°ì¡´ í˜•ì‹ ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)
                            for detection in results[0]:
                                if detection[1]:  # Has text result
                                    text = detection[1][0]
                                    confidence = detection[1][1]
                                    
                                    # ë¡œê·¸ í…ìŠ¤íŠ¸ í•„í„°ë§
                                    if self._is_log_text(text):
                                        if self.debug_mode:
                                            self.logger.debug(f"{cell_id}: ë¡œê·¸ í…ìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸° - '{text}'")
                                        continue
                                    
                                    # Log only high confidence detections in debug mode
                                    if self.debug_mode and confidence > 0.7:
                                        self.logger.debug(f"{cell_id} Strategy {i}: '{text}' (conf: {confidence:.2f})")
                                    
                                    all_results.append({
                                        'text': text,
                                        'confidence': confidence,
                                        'strategy': i
                                    })
                                    
                                    # Update best result
                                    # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒ
                                    is_trigger_text = any(pattern in text for pattern in self.config.get('trigger_patterns', []))
                                    
                                    # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ìˆê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë” ë†’ì€ ê²½ìš° ì—…ë°ì´íŠ¸
                                    should_update = False
                                    if is_trigger_text and confidence > 0.3:
                                        # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ìˆê³  ì‹ ë¢°ë„ê°€ ì¶©ë¶„í•˜ë©´ ì„ íƒ
                                        should_update = True
                                    elif confidence > best_confidence and not any(pattern in best_result.text if best_result else '' for pattern in self.config.get('trigger_patterns', [])):
                                        # í˜„ì¬ ìµœê³  ê²°ê³¼ê°€ íŠ¸ë¦¬ê±°ê°€ ì•„ë‹ˆê³ , ìƒˆ ê²°ê³¼ê°€ ë” ë†’ì€ ì‹ ë¢°ë„ë©´ ì„ íƒ
                                        should_update = True
                                    
                                    if should_update:
                                        best_confidence = confidence
                                        position = (int(detection[0][0][0]), int(detection[0][0][1]))
                                        best_result = OCRResult(
                                            text, 
                                            confidence, 
                                            position,
                                            debug_info={
                                                'strategy': i,
                                                'all_results': all_results
                                            }
                                        )
                                    
                except Exception as e:
                    self.logger.debug(f"OCR failed on strategy {i}: {e}")
                    continue
            
            # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ìˆëŠ” ê²°ê³¼ë¥¼ ìš°ì„  í™•ì¸
            best_trigger_result = None
            best_trigger_confidence = 0
            
            for res in all_results:
                text = res.get('text', '')
                conf = res.get('confidence', 0)
                
                # ë¡œê·¸ í…ìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°
                if self._is_log_text(text):
                    continue
                    
                for pattern in self.config.get('trigger_patterns', []):
                    if pattern in text and conf > best_trigger_confidence:
                        best_trigger_confidence = conf
                        best_trigger_result = OCRResult(
                            text,
                            conf,
                            debug_info={'all_results': all_results, 'trigger_found': True}
                        )
                        self.logger.info(f"ğŸ¯ íŠ¸ë¦¬ê±° íŒ¨í„´ ë°œê²¬: '{text}' (ì‹ ë¢°ë„: {conf:.2f})")
            
            # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ìˆìœ¼ë©´ ìš°ì„  ë°˜í™˜
            if best_trigger_result:
                self.ocr_stats['successful_detections'] += 1
                return best_trigger_result
            
            # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ best_result ë°˜í™˜
            if best_result:
                self.ocr_stats['successful_detections'] += 1
                self.logger.info(f"âœ… OCR ìµœì¢… ì„ íƒ: '{best_result.text}' (ì‹ ë¢°ë„: {best_result.confidence:.2f})")
                return best_result
            else:
                # best_resultê°€ ì—†ì–´ë„ all_resultsì—ì„œ íŠ¸ë¦¬ê±° íŒ¨í„´ ì°¾ê¸°
                for res in all_results:
                    text = res.get('text', '')
                    if text and any(pattern in text for pattern in self.config.get('trigger_patterns', [])):
                        # íŠ¸ë¦¬ê±° íŒ¨í„´ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê²°ê³¼ ë°˜í™˜
                        return OCRResult(
                            text,
                            res.get('confidence', 0.9),
                            debug_info={'all_results': all_results, 'fallback': True}
                        )
                
                self.ocr_stats['empty_results'] += 1
                return OCRResult(debug_info={'all_results': all_results})
                
        except Exception as e:
            self.ocr_stats['errors'] += 1
            self.ocr_stats['last_error_time'] = time.time()
            
            error_msg = str(e).lower()
            
            # Enhanced error handling with match-case
            match error_msg:
                case msg if "primitive" in msg:
                    self.logger.error(f"PaddleOCR primitive error for {cell_id}, marking for recovery")
                    self.paddle_ocr = None
                    EnhancedOCRService._shared_paddle_ocr = None
                case msg if "memory" in msg or "allocation" in msg:
                    self.logger.error(f"Memory error for {cell_id}, forcing cleanup")
                    gc.collect()
                case msg if "timeout" in msg:
                    self.logger.warning(f"OCR timeout for {cell_id}, may need optimization")
                case _:
                    self.logger.error(f"OCR processing failed for {cell_id}: {e}")
                
            return OCRResult(debug_info={'error': str(e)})
    
    def _check_ocr_health(self) -> bool:
        """Check if OCR engine is healthy."""
        if not self.paddle_ocr:
            return False
            
        # Check error rate
        if self.ocr_stats['total_attempts'] > 10:
            error_rate = self.ocr_stats['errors'] / self.ocr_stats['total_attempts']
            if error_rate > 0.5:  # More than 50% errors
                self.logger.warning(f"High OCR error rate: {error_rate:.2%}")
                return False
        
        # Check if too many empty results
        if self.ocr_stats['total_attempts'] > 10:
            empty_rate = self.ocr_stats['empty_results'] / self.ocr_stats['total_attempts']
            if empty_rate > 0.8:  # More than 80% empty
                self.logger.warning(f"High empty result rate: {empty_rate:.2%}")
                # Don't mark as unhealthy, but log for debugging
        
        return True
    
    def _recover_ocr_engine(self):
        """Attempt to recover OCR engine."""
        self.logger.info("Attempting OCR engine recovery...")
        
        # Reset shared instance
        with EnhancedOCRService._ocr_lock:
            EnhancedOCRService._shared_paddle_ocr = None
            EnhancedOCRService._last_init_time = 0
        
        # Reinitialize
        self._initialize_paddle_ocr()
        
        # Reset error stats
        self.ocr_stats['errors'] = 0
        self.ocr_stats['empty_results'] = 0
        
    def check_trigger_patterns(self, ocr_result: OCRResult) -> bool:
        """Check if OCR result matches any trigger patterns."""
        if not ocr_result.is_valid():
            return False
        
        text = ocr_result.text
        
        # ë¡œê·¸ í…ìŠ¤íŠ¸ í•„í„°ë§ - OCRì´ ë¡œê·¸ ì°½ì„ ì½ëŠ” ê²ƒ ë°©ì§€
        if self._is_log_text(text):
            self.logger.debug(f"ë¡œê·¸ í…ìŠ¤íŠ¸ í•„í„°ë§: '{text}'")
            return False
        
        # Filter out obvious non-Korean text
        if self._is_non_korean_text(text):
            self.logger.debug(f"Filtered non-Korean text: '{text}'")
            return False
        
        # Use enhanced OCR corrector
        is_match, matched_pattern = self.ocr_corrector.check_trigger_pattern(text)
        
        if is_match:
            self.logger.info(f"ğŸ¯ Trigger pattern detected: '{text}' -> '{matched_pattern}'")
            return True
        
        return False
    
    def _is_log_text(self, text: str) -> bool:
        """ë¡œê·¸ ì°½ì˜ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
        # ë¡œê·¸ íŒ¨í„´ë“¤
        log_patterns = [
            r'\[\d{2}:\d{2}:\d{2}\]',  # [02:23:40] ê°™ì€ íƒ€ì„ìŠ¤íƒ¬í”„
            r'OCR \uac10\uc9c0:',  # 'OCR ê°ì§€:' í…ìŠ¤íŠ¸
            r'\uac10\uc9c0:',  # 'ê°ì§€:' í…ìŠ¤íŠ¸
            r'\uc790\ub3d9\ud654:',  # 'ìë™í™”:' í…ìŠ¤íŠ¸
            r'\[TARGET\]',  # '[TARGET]' í…ìŠ¤íŠ¸
            r'\[OK\]',  # '[OK]' í…ìŠ¤íŠ¸
            r'\uc2e0\ub8b0\ub3c4:',  # 'ì‹ ë¢°ë„:' í…ìŠ¤íŠ¸
            r'monitor_\d+_cell_\d+_\d+',  # ì…€ ID íŒ¨í„´
        ]
        
        for pattern in log_patterns:
            if re.search(pattern, text):
                return True
        
        # ë¡œê·¸ì—ì„œ í”íˆ ë³¼ ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜ ë¬¸ì ì¡°í•©
        if "'(" in text and ")" in text:  # '(ì‹ ë¢°ë„:' ê°™ì€ íŒ¨í„´
            return True
            
        return False
    
    def _is_non_korean_text(self, text: str) -> bool:
        """Check if text is likely non-Korean (like timestamps, IDs, etc)."""
        if not text:
            return True
        
        # Check for patterns like "-1 1A 11" (timestamps, IDs)
        if re.match(r'^[-\d\s\w]+$', text) and not any(ord(c) >= 0xAC00 and ord(c) <= 0xD7A3 for c in text):
            return True
        
        # Count Korean characters
        korean_chars = sum(1 for c in text if ord(c) >= 0xAC00 and ord(c) <= 0xD7A3)
        total_chars = len(text.replace(' ', ''))
        
        # If less than 30% Korean characters, likely not Korean text
        if total_chars > 0 and korean_chars / total_chars < 0.3:
            return True
        
        return False
    
    def is_available(self) -> bool:
        """Check if OCR service is available."""
        return self.paddle_ocr is not None
    
    def get_status(self) -> dict[str, Any]:
        """Get detailed OCR service status."""
        total = self.ocr_stats['total_attempts']
        success_rate = (self.ocr_stats['successful_detections'] / total * 100) if total > 0 else 0
        empty_rate = (self.ocr_stats['empty_results'] / total * 100) if total > 0 else 0
        error_rate = (self.ocr_stats['errors'] / total * 100) if total > 0 else 0
        
        return {
            'available': self.is_available(),
            'paddleocr_installed': PADDLEOCR_AVAILABLE,
            'engine_initialized': self.paddle_ocr is not None,
            'stats': {
                'total_attempts': total,
                'success_rate': f"{success_rate:.1f}%",
                'empty_rate': f"{empty_rate:.1f}%",
                'error_rate': f"{error_rate:.1f}%",
                'debug_saves': f"{self.debug_save_count}/{self.max_debug_saves}"
            }
        }
    
    def reset_debug_saves(self):
        """Reset debug save counter."""
        self.debug_save_count = 0
        self.logger.info("Debug save counter reset")
    
    def get_statistics(self) -> dict[str, Any]:
        """Get OCR service statistics (alias for get_status)."""
        return self.get_status()